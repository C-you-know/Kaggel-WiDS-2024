{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Team Codeaholics__ –  WIDS Jupyter Notebook #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __HEADER FILES__  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimpy import skim\n",
    "import category_encoders as ce\n",
    "from xgboost import XGBRegressor \n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, RobustScaler\n",
    "from catboost import CatBoostRegressor, EShapCalcType, EFeaturesSelectionAlgorithm\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, ExtraTreesClassifier, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Setting up the environment_ ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Citations and Credits_ ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Code has been adapted from these sources: \n",
    "- [simonagradinaru] (https://www.kaggle.com/code/simonagradinaru/wids-24-2-embracing-diversity-robustness)\n",
    "- [ogwalakello] (https://www.kaggle.com/code/ogwalakello/wids-datathon-2024-1st-place-solution)\n",
    "- [sid4ds] (https://www.kaggle.com/code/sid4ds/wids-2-00-overview-cv-setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __LOADING THE DATA__  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv('test.csv')\n",
    "solution_template = pd.read_csv('solution_template.csv')\n",
    "\n",
    "print(\"Train, Test, and  dataset loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Train Dataset__ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Test Dataset__ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Solution Template__ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_template.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Statistics of the raw data_ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skim(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __DATA PREPROCESSING__  ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Removing unreliable columns_ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_remove = ['patient_gender', 'breast_cancer_diagnosis_desc']\n",
    "\n",
    "training = training.drop(columns_to_remove, axis=1)\n",
    "test = test.drop(columns_to_remove, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Removing unreliable rows_ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training[training['family_size'].isna() != 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Correcting outliers and errors_ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix bad zip \n",
    "training['patient_state'] = np.where(training['patient_zip3'] == 630, 'MO', np.where(training['patient_zip3'] == 864, 'AZ', training['patient_state']))\n",
    "\n",
    "# Male codes to female \n",
    "training['breast_cancer_diagnosis_code'] = training['breast_cancer_diagnosis_code'].replace({\n",
    "    'C50122':'C50112', 'C50221':'C50211', 'C50421':'C50411', 'C509':'C5091', 'C50922':'C50912'\n",
    "})\n",
    "\n",
    "# Recode categories in test data \n",
    "test['breast_cancer_diagnosis_code'] = test['breast_cancer_diagnosis_code'].replace({'C5021':'C50219'})\n",
    "\n",
    "# Population columns\n",
    "pop_cols = training.loc[:, 'population':'veteran'].columns.to_list()\n",
    "\n",
    "# Fix outliers \n",
    "training.loc[training.patient_id == 441322, pop_cols] = training.loc[training.patient_id == 982003, pop_cols].values\n",
    "training.loc[training.patient_id == 271422, pop_cols] = training.loc[training.patient_id == 271245, pop_cols].values\n",
    "training.loc[training.patient_id == 714510, pop_cols] = training.loc[training.patient_id == 636245, pop_cols].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Filling Nan values in Categorical Data_ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing Payer Type\n",
    "training['payer_type'] = training['payer_type'].fillna('None')\n",
    "test['payer_type'] = test['payer_type'].fillna('None')\n",
    "\n",
    "# Imputing Patient Race\n",
    "training['patient_race'] = training['patient_race'].fillna('Not Recorded')\n",
    "test['patient_race'] = test['patient_race'].fillna('Not Recorded')\n",
    "\n",
    "# Imputing Metastatic Novel Treatment\n",
    "training['metastatic_first_novel_treatment'] = training['metastatic_first_novel_treatment'].fillna('Not Recorded')\n",
    "test['metastatic_first_novel_treatment'] = test['metastatic_first_novel_treatment'].fillna('Not Recorded')\n",
    "\n",
    "# Imputing Metastatic Novel Treatment Type\n",
    "training['metastatic_first_novel_treatment_type'] = training['metastatic_first_novel_treatment_type'].fillna('Not Recorded')\n",
    "test['metastatic_first_novel_treatment_type'] = test['metastatic_first_novel_treatment_type'].fillna('Not Recorded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Custom encoding of the Division and Age attributes_ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding based on the Graph\n",
    "custom_mapping1 = {\n",
    "    'East South Central': 1,\n",
    "    'Middle Atlantic': 7,\n",
    "    'South Atlantic': 3,\n",
    "    'East North Central': 4,\n",
    "    'West South Central': 5,\n",
    "    'West North Central': 6,\n",
    "    'Pacific' : 2,\n",
    "    'Mountain':8\n",
    "}\n",
    "\n",
    "training['div_encoded'] = training['Division'].map(custom_mapping1)\n",
    "test['div_encoded'] = test['Division'].map(custom_mapping1)\n",
    "\n",
    "\n",
    "# Define the ranges and corresponding labels\n",
    "bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]  # Define the edges of the bins\n",
    "labels = [1, 2, 3, 4, 5, 6, 7, 0, -1, -2]      # Define the labels for each bin\n",
    "\n",
    "training['age_encoded'] = pd.cut(training['patient_age'], bins=bins, labels=labels, right=False)\n",
    "test['age_encoded'] = pd.cut(test['patient_age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "training['age_encoded'] = training['age_encoded'].astype(int)\n",
    "test['age_encoded'] = test['age_encoded'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Standard Imputation Function_ ###\n",
    "- Mean for numerical data\n",
    "- Mode for the remaning categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values\n",
    "def mixed_imputation(df, group_col):\n",
    "    for column in df.columns:\n",
    "        if column != group_col:  # Exclude the group column\n",
    "            # If the column is numerical, then mean imputation\n",
    "            if df[column].dtype in [np.dtype('float_'), np.dtype('int_')]:  \n",
    "                mean_impute = df.groupby(group_col)[column].mean()\n",
    "                df[column] = df[column].fillna(df[group_col].map(mean_impute))\n",
    "            # If the column is categorical, apply mode imputation\n",
    "            else :  \n",
    "                mode_impute = df.groupby(group_col)[column].apply(lambda x: x.mode()[0] if not x.mode().empty else np.nan)\n",
    "                df[column] = df[column].fillna(df[group_col].map(mode_impute))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Imputing the population columns_ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset population data \n",
    "training_pop = training[['patient_zip3', 'patient_state'] + pop_cols].drop_duplicates().sort_values(by='patient_zip3').reset_index(drop=True)\n",
    "\n",
    "# Impute missing values \n",
    "training_pop = mixed_imputation(df=training_pop, group_col='patient_zip3')\n",
    "training_pop = mixed_imputation(df=training_pop, group_col='patient_state')\n",
    "\n",
    "print(training_pop.shape)\n",
    "training_pop.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Imputing the temperature columns_ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Subset temperatures \n",
    "avg_cols = training.columns[training.columns.str.startswith('Average')].tolist()\n",
    "training_avg = training[['patient_zip3', 'patient_state'] + avg_cols].drop_duplicates().sort_values(by='patient_zip3').reset_index(drop=True)\n",
    "\n",
    "print(training_avg.shape)\n",
    "training_avg.head()\n",
    "\n",
    "# Melt data\n",
    "training_avg_melt = pd.melt(training_avg, id_vars=['patient_zip3', 'patient_state'])\n",
    "\n",
    "# Extract month and convert it to datetime\n",
    "training_avg_melt['month'] = training_avg_melt['variable'].apply(lambda x: x[len(x)-6:])\n",
    "training_avg_melt['month'] = pd.to_datetime(training_avg_melt['month'], format='%b-%y')\n",
    "\n",
    "# # Create growth from prior month\n",
    "training_avg_melt.sort_values(by=['patient_zip3', 'patient_state', 'month'], inplace=True)\n",
    "\n",
    "# Fill missingness - forward, then backwards for remaining \n",
    "training_avg_melt['value'] = training_avg_melt.groupby(['patient_zip3', 'patient_state'])['value'].ffill()\n",
    "training_avg_melt['value'] = training_avg_melt.groupby(['patient_zip3', 'patient_state'])['value'].bfill()\n",
    "training_avg_melt.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Adding new features derived from the temperature subset_ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reshape data \n",
    "training_avgs = training_avg_melt.drop('month', axis=1).pivot(index=['patient_zip3', 'patient_state'],columns='variable', values='value').reset_index()[['patient_zip3', 'patient_state'] + avg_cols]\n",
    "\n",
    "# More features \n",
    "training_avgs['Avg-13'] = training_avgs.loc[:, 'Average of Jan-13':'Average of Dec-13'].mean(axis=1)\n",
    "training_avgs['Avg-14'] = training_avgs.loc[:, 'Average of Jan-14':'Average of Dec-14'].mean(axis=1)\n",
    "training_avgs['Avg-15'] = training_avgs.loc[:, 'Average of Jan-15':'Average of Dec-15'].mean(axis=1)\n",
    "training_avgs['Avg-16'] = training_avgs.loc[:, 'Average of Jan-16':'Average of Dec-16'].mean(axis=1)\n",
    "training_avgs['Avg-17'] = training_avgs.loc[:, 'Average of Jan-17':'Average of Dec-17'].mean(axis=1)\n",
    "training_avgs['Avg-18'] = training_avgs.loc[:, 'Average of Jan-18':'Average of Dec-18'].mean(axis=1)\n",
    "\n",
    "print(training_avgs.shape)\n",
    "training_avgs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Combine the subset datasets_ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_full = training.drop(pop_cols + avg_cols, axis=1).merge(\n",
    "    training_pop, how='left', on=['patient_zip3', 'patient_state']\n",
    ").merge(\n",
    "    training_avgs, how='left', on=['patient_zip3', 'patient_state']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Extracting new features_ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Categorize variables\n",
    "training_full['age_group'] = pd.cut(training_full['patient_age'], right=False, bins=[0, 30, 40, 50, 60, 70, 80, 90, np.inf], labels=[0,1,2,3,4,5,6,7]).astype(int)\n",
    "training_full['icd_9'] = training_full['breast_cancer_diagnosis_code'].str.startswith('17').astype(int)\n",
    "\n",
    "# Include bmi info \n",
    "training_full['bmi_missing'] = training_full['bmi'].isna().astype(int)\n",
    "training_full['bmi_recoded'] = np.where(training_full['bmi'].isna(), 0, \n",
    "                                  np.where(training_full['bmi'] < 18.5, 1, \n",
    "                                          np.where(training_full['bmi'] < 25, 2, \n",
    "                                                 np.where(training_full['bmi'] < 30, 3, 4))))\n",
    "training_full.columns = training_full.columns.str.replace(' ', '_').str.replace('-', '')\n",
    "\n",
    "\n",
    "print(training_full.shape)\n",
    "training_full.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Same techniques are applied on the test dataset_ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fix bad zip \n",
    "test['patient_state'] = np.where(test['patient_zip3'] == 630, 'MO', \n",
    "                                    np.where(test['patient_zip3'] == 864, 'AZ', test['patient_state']))\n",
    "\n",
    "# Melt data\n",
    "df_avg_melt_test = pd.melt(test[['patient_zip3', 'patient_state'] + avg_cols].drop_duplicates().sort_values(by='patient_zip3').reset_index(drop=True), id_vars=['patient_zip3', 'patient_state'])\n",
    "\n",
    "# Extract month and convert it to datetime\n",
    "df_avg_melt_test['month'] = df_avg_melt_test['variable'].apply(lambda x: x[len(x)-6:])\n",
    "df_avg_melt_test['month'] = pd.to_datetime(df_avg_melt_test['month'], format='%b-%y')\n",
    "df_avg_melt_test.sort_values(by=['patient_zip3', 'patient_state', 'month'], inplace=True)\n",
    "\n",
    "# Fill missingness - forward, then backwards for remaining \n",
    "df_avg_melt_test['value'] = df_avg_melt_test.groupby(['patient_zip3', 'patient_state'])['value'].ffill()\n",
    "df_avg_melt_test['value'] = df_avg_melt_test.groupby(['patient_zip3', 'patient_state'])['value'].bfill()\n",
    "\n",
    "# Reshape data \n",
    "df_avgs_test = df_avg_melt_test.drop('month', axis=1).pivot(index=['patient_zip3', 'patient_state'],columns='variable', values='value').reset_index()[['patient_zip3', 'patient_state'] + avg_cols]\n",
    "\n",
    "# More features \n",
    "df_avgs_test['Avg-13'] = df_avgs_test.loc[:, 'Average of Jan-13':'Average of Dec-13'].mean(axis=1)\n",
    "df_avgs_test['Avg-14'] = df_avgs_test.loc[:, 'Average of Jan-14':'Average of Dec-14'].mean(axis=1)\n",
    "df_avgs_test['Avg-15'] = df_avgs_test.loc[:, 'Average of Jan-15':'Average of Dec-15'].mean(axis=1)\n",
    "df_avgs_test['Avg-16'] = df_avgs_test.loc[:, 'Average of Jan-16':'Average of Dec-16'].mean(axis=1)\n",
    "df_avgs_test['Avg-17'] = df_avgs_test.loc[:, 'Average of Jan-17':'Average of Dec-17'].mean(axis=1)\n",
    "df_avgs_test['Avg-18'] = df_avgs_test.loc[:, 'Average of Jan-18':'Average of Dec-18'].mean(axis=1)\n",
    "\n",
    "\n",
    "# Bring all necessary data together\n",
    "df_test_full = test.drop(avg_cols, axis=1).merge(\n",
    "    df_avgs_test, how='left', on=['patient_zip3', 'patient_state']\n",
    ")\n",
    "\n",
    "# Categorize variables\n",
    "df_test_full['age_group'] = pd.cut(df_test_full['patient_age'], right=False, bins=[0, 30, 40, 50, 60, 70, 80, 90, np.inf], labels=[0,1,2,3,4,5,6,7]).astype(int)\n",
    "df_test_full['icd_9'] = df_test_full['breast_cancer_diagnosis_code'].str.startswith('17').astype(int)\n",
    "\n",
    "# Include bmi info \n",
    "df_test_full['bmi_missing'] = df_test_full['bmi'].isna().astype(int)\n",
    "df_test_full['bmi_recoded'] = np.where(df_test_full['bmi'].isna(), 0, \n",
    "                                  np.where(df_test_full['bmi'] < 18.5, 1, \n",
    "                                          np.where(df_test_full['bmi'] < 25, 2, \n",
    "                                                 np.where(df_test_full['bmi'] < 30, 3, 4))))\n",
    "\n",
    "df_test_full.columns = df_test_full.columns.str.replace(' ', '_').str.replace('-', '')\n",
    "\n",
    "print(df_test_full.shape)\n",
    "df_test_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Statistics of the cleaned data_ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skim(training_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___Preparing the data for modeling___ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_full.drop(['patient_id', 'bmi', 'metastatic_diagnosis_period'], axis=1)\n",
    "y = training_full['metastatic_diagnosis_period']\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_categorical = X.columns[X.dtypes == 'object'].to_list()\n",
    "\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1).fit(X[cols_categorical])\n",
    "X_enc = pd.concat([\n",
    "    X[X.columns[~X.columns.isin(cols_categorical)]],\n",
    "    pd.DataFrame(encoder.transform(X[cols_categorical]), columns=cols_categorical)], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_enc, y, random_state=seed, stratify=y, test_size=.2)\n",
    "print('Training size: ', X_train.shape)\n",
    "print('Testing size: ', X_test.shape)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Recurcive Feature Elimination using CatBoost Regression__ ##\n",
    "\n",
    "Code has been adapted from these sources: \n",
    "- [catboost] (https://github.com/catboost/catboost/blob/master/catboost/tutorials/feature_selection/select_features_tutorial.ipynb )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit initial model\n",
    "ctb_full = CatBoostRegressor(\n",
    "    random_state=seed, \n",
    "    verbose=False, \n",
    "    eval_metric='RMSE'\n",
    ").fit(X_train, y_train, eval_set=(X_test, y_test), use_best_model=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_rfe = False\n",
    "if rerun_rfe == True:\n",
    "    rfe_ctb_full = ctb_full.select_features(\n",
    "        X                      = X_train, \n",
    "        y                      = y_train, \n",
    "        eval_set               = (X_test, y_test), \n",
    "        features_for_select    = X_train.columns.to_list(),                         # Features that will be selected on the RFE - here, all of them\n",
    "        num_features_to_select = 10,                                                # Number of features to keep from the selected\n",
    "        algorithm              = EFeaturesSelectionAlgorithm.RecursiveByShapValues, # Algorithm chosen, see -> \n",
    "        steps                  = 20,                                                # Number of model iterations performed in the RFE\n",
    "        verbose                = False,                                             # Do not print model iterations\n",
    "        train_final_model      = False,                                             # Train final model after RFE is finished \n",
    "        plot                   = True                                               # plot after the RFE is finished -> very helpful for understanding if we can get a better AUC with fewer variables\n",
    "    )\n",
    "    \n",
    "    # Minimum loss corresponds to the lowest RMSE \n",
    "    n_todrop = np.argmin(rfe_ctb_full['loss_graph']['loss_values'])\n",
    "    cols_to_keep = X.drop(rfe_ctb_full['eliminated_features_names'][:n_todrop],axis=1).columns.to_list()\n",
    "else: \n",
    "    cols_to_keep = [\n",
    "         'patient_age',\n",
    "         'self_employed',\n",
    "         'Average_of_Apr13',\n",
    "         'Average_of_Sep13',\n",
    "         'Average_of_Aug14',\n",
    "         'Average_of_Aug16',\n",
    "         'Average_of_May18',\n",
    "         'age_group',\n",
    "         'bmi_missing',\n",
    "         'bmi_recoded',\n",
    "         'payer_type',\n",
    "         'breast_cancer_diagnosis_code',\n",
    "         'metastatic_cancer_diagnosis_code',\n",
    "         'icd_9',\n",
    "         'Region',\n",
    "         'age_encoded',\n",
    "         'age_40s',\n",
    "         'Division',\n",
    "         'education_highschool',\n",
    "         'Avg14',\n",
    "         'education_college_or_above',\n",
    "         'metastatic_first_novel_treatment',\n",
    "         'metastatic_first_novel_treatment_type'\n",
    "        ]\n",
    "    \n",
    "X_short = X_enc[cols_to_keep]\n",
    "X_train_short = X_train[cols_to_keep]\n",
    "X_test_short = X_test[cols_to_keep]\n",
    "\n",
    "print(X_short.shape)\n",
    "X_short.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __TRAINING AN ENSEMBLE MODEL__ \n",
    "\n",
    "### _The following model were used_ ###\n",
    "- CATBOOST\n",
    "- LIGHTGBM\n",
    "- LIGHTGBM WITH TWEEDIE\n",
    "- XGB REGRESSOR\n",
    "- RANDOM FOREST\n",
    "- GRADIENT BOOSTING\n",
    "- ADABOOST\n",
    "- EXTRA TREES\n",
    "- K NEIGHBOURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CatBoost Regresion (Hypertuned)\n",
    "ctb = CatBoostRegressor(\n",
    "    random_state=seed, \n",
    "    learning_rate=0.029143404630341967,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=2.0599682627368536,\n",
    "    bagging_temperature=0.13525392267548214,\n",
    "    verbose= False, \n",
    "    eval_metric='RMSE'\n",
    ").fit(X_train_short, y_train, eval_set=(X_test_short, y_test), use_best_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LightGBM Regresion (Hypertuned)\n",
    "lgbm = LGBMRegressor(\n",
    "    random_state=seed, \n",
    "    learning_rate=.06,\n",
    "    max_depth = 4,\n",
    "    verbose=-1\n",
    ").fit(X_train_short, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. LightGBM with Tweedie objective (Hypertuned)\n",
    "lgbm_tw = LGBMRegressor(\n",
    "    random_state=seed,\n",
    "    tweedie_variance=1.1, \n",
    "    n_estimators=40,\n",
    "    verbosity=-1,\n",
    "    objective=\"tweedie\",\n",
    "    metric=\"rmse\"\n",
    ").fit(X_train_short, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. XGB Regression (Hypertuned)\n",
    "xgb = XGBRegressor(\n",
    "    random_state=seed,\n",
    "    learning_rate=0.05075565490876331,\n",
    "    max_depth=5,\n",
    "    n_estimators= 132,\n",
    "    min_child_weight= 3,\n",
    "    gamma= 0.000162007012716049,\n",
    "    subsample= 0.8103835140746048,\n",
    "    colsample_bytree= 0.6747747924854386,\n",
    "    reg_alpha= 0.0007688985669753765,\n",
    "    reg_lambda= 0.000177315807077408\n",
    ").fit(X_train_short, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Random Forest Regression (Hypertuned)\n",
    "rf = RandomForestRegressor(\n",
    "    random_state=seed,\n",
    "    n_estimators=81,\n",
    "    max_depth=9,\n",
    "    min_samples_split=17,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=False\n",
    ").fit(X_train_short, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Gradient Boosting Regression (Hypertuned)\n",
    "gb = GradientBoostingRegressor(\n",
    "    random_state=seed,\n",
    "    n_estimators=170,\n",
    "    learning_rate=0.05352169500172268,\n",
    "    max_depth=4,\n",
    "    min_samples_split=17,\n",
    "    min_samples_leaf=4,\n",
    "    max_features='sqrt'\n",
    ").fit(X_train_short, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. AdaBoost Regression (Hypertuned)\n",
    "ada = AdaBoostRegressor(\n",
    "    random_state=seed,\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.00053678329477655296,\n",
    "    loss='linear'\n",
    ").fit(X_train_short, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. ExtraTrees Regression (Hypertuned)\n",
    "et = ExtraTreesRegressor(\n",
    "    random_state=seed,\n",
    "    n_estimators=100,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='log2',\n",
    "    max_depth=10,\n",
    "    bootstrap=False\n",
    ").fit(X_train_short, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. KNeighbors Regressor (Hypertuned)\n",
    "kn = KNeighborsRegressor(\n",
    "    n_neighbors=47,\n",
    "    weights= 'uniform',\n",
    "    algorithm='brute',\n",
    "    leaf_size= 72,\n",
    "    p=2\n",
    ").fit(X_train_short, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __EVALUATE THE MODEL__ ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Funtion Declarations_ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def CV_predict(X, y, newdata, model, custom_cv, stratify_col=None, verbose=True, use_best_model=False):\n",
    "    oof_preds, test_preds = {}, {}\n",
    "    scores = []\n",
    "\n",
    "    for fold, (train_ids, val_ids) in enumerate(custom_cv.split(X, stratify_col)):\n",
    "        X_tr, y_tr = X.iloc[train_ids], y.iloc[train_ids]\n",
    "        X_val, y_val = X.iloc[val_ids], y.iloc[val_ids]\n",
    "        \n",
    "        if use_best_model == True:\n",
    "            model.fit(\n",
    "                X_tr, y_tr,\n",
    "                eval_set=[(X_val, y_val)],\n",
    "                use_best_model=True,\n",
    "                verbose=False)\n",
    "            \n",
    "        elif type(model) == XGBRegressor:\n",
    "            model.fit(X_tr, y_tr, verbose=False)\n",
    "            \n",
    "        else: \n",
    "            model.fit(X_tr, y_tr)\n",
    "\n",
    "        val_preds = model.predict(X_val)\n",
    "        oof_preds.update(dict(zip(val_ids, val_preds)))\n",
    "        test_preds[f'fold{fold}'] = model.predict(newdata)\n",
    "\n",
    "        score = rmse(y_val, val_preds)\n",
    "        scores.append(score)\n",
    "        if verbose:\n",
    "            if type(model) == CatBoostRegressor:\n",
    "                print(f'Fold #{fold:>2}: {score:.5f} ({model.best_iteration_:>4} rounds)')\n",
    "            else: \n",
    "                print(f'Fold #{fold:>2}: {score:.5f}')\n",
    "\n",
    "    test_preds = pd.DataFrame.from_dict(test_preds)\n",
    "    test_preds['mean'] = test_preds.mean(axis=1) # mean of fold-wise predictions\n",
    "    \n",
    "    oof_preds = pd.Series(oof_preds).sort_index()\n",
    "    print(f'\\nAvg score: {np.mean(scores):.5f} ± {np.std(scores):.5f}')\n",
    "    print(f'OOF score: {rmse(y, oof_preds):.5f}')\n",
    "    \n",
    "    return oof_preds, test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Stratified K Fold Validation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, cross validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "icd = training_full['breast_cancer_diagnosis_code'].str.startswith('17').astype(int)\n",
    "\n",
    "df_test_enc = pd.concat([\n",
    "    df_test_full[df_test_full.columns[~df_test_full.columns.isin(cols_categorical)]],\n",
    "    pd.DataFrame(encoder.transform(df_test_full[cols_categorical]), columns=cols_categorical)], axis=1)\n",
    "\n",
    "df_test_short = df_test_enc[X_short.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "oof_preds_ctb, test_preds_ctb = CV_predict(X_short, y, df_test_short, ctb, cv, use_best_model=True, stratify_col=icd) \n",
    "oof_preds_xgb, test_preds_xgb = CV_predict(X_short, y, df_test_short, xgb, cv, stratify_col=icd) \n",
    "oof_preds_rf, test_preds_rf = CV_predict(X_short, y, df_test_short, rf, cv, stratify_col=icd) \n",
    "oof_preds_gb, test_preds_gb = CV_predict(X_short, y, df_test_short, gb, cv, stratify_col=icd) \n",
    "oof_preds_ada, test_preds_ada = CV_predict(X_short, y, df_test_short, ada, cv, stratify_col=icd) \n",
    "oof_preds_et, test_preds_et = CV_predict(X_short, y, df_test_short, et, cv, stratify_col=icd) \n",
    "oof_preds_kn, test_preds_kn = CV_predict(X_short, y, df_test_short, kn, cv, stratify_col=icd) \n",
    "oof_preds_lgbm_tw, test_preds_lgbm_tw = CV_predict(X_short, y, df_test_short, lgbm_tw, cv, stratify_col=icd) \n",
    "oof_preds_lgbm, test_preds_lgbm = CV_predict(X_short, y, df_test_short, lgbm, cv, stratify_col=icd) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPING THE TEST DATASET ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_combined = pd.DataFrame({\n",
    "    'model1': oof_preds_ctb,\n",
    "    'model2': oof_preds_xgb,\n",
    "    'model3': oof_preds_lgbm, \n",
    "    'model4': oof_preds_rf,\n",
    "    'model5': oof_preds_gb,\n",
    "    'model6': oof_preds_ada,\n",
    "    'model7': oof_preds_et,\n",
    "    'model8': oof_preds_lgbm_tw,\n",
    "    'model9': oof_preds_kn\n",
    "})\n",
    "\n",
    "test_preds_combined = pd.DataFrame({\n",
    "    'model1': test_preds_ctb['mean'],\n",
    "    'model2': test_preds_xgb['mean'],\n",
    "    'model3': test_preds_lgbm['mean'],\n",
    "    'model4': test_preds_rf['mean'],\n",
    "    'model5': test_preds_gb['mean'],\n",
    "    'model6': test_preds_ada['mean'],\n",
    "    'model7': test_preds_et['mean'],\n",
    "    'model8': test_preds_lgbm_tw['mean'],\n",
    "    'model9': test_preds_kn['mean']\n",
    "})\n",
    "test_preds_combined.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check rmse\n",
    "oof_preds_combined.apply(lambda x: rmse(y, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Ridge Cross Validation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cv = RidgeCV(\n",
    "    alphas=[.001, .01, .05, .1, 1, 5, 10, 20, 50, 100],\n",
    "    scoring='neg_root_mean_squared_error', \n",
    "    cv=5\n",
    ")\n",
    "\n",
    "meta_cv.fit(oof_preds_combined, y)\n",
    "print('R2 =', meta_cv.score(oof_preds_combined, y))\n",
    "print('RMSE =', rmse(y, meta_cv.predict(oof_preds_combined))) \n",
    "meta_cv.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Ridge Regression_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate ridge to use predictions\n",
    "ridge = Ridge(alpha=meta_cv.alpha_, random_state=seed)\n",
    "oof_preds_final, test_preds_final = CV_predict(oof_preds_combined, y, test_preds_combined, ridge, cv, stratify_col=icd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Creating a new CSV file to upload_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_final = solution_template.copy()\n",
    "sub_final['metastatic_diagnosis_period'] = test_preds_final['mean']\n",
    "sub_final['metastatic_diagnosis_period'] = sub_final['metastatic_diagnosis_period'].apply(lambda x: np.clip(x, a_min=0, a_max=np.inf))\n",
    "sub_final.to_csv('upload.csv', index=False)\n",
    "sub_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = training_full[['patient_id', 'patient_race']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
